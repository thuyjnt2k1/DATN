,id,type,name,link,count
0,1,1,Optimizing Audio-Visual Speech Enhancement Using Multi-Level Distortion Measures for Audio-Visual Speech Recognition,/document/10508446/,1
1,2,2,Hang Chen,/author/37089469481,1
2,3,2,Qing Wang,/author/37089778067,2
3,4,2,Jun Du,/author/37649186400,2
4,5,2,Bao-Cai Yin,/author/37268507700,1
5,6,2,Jia Pan,/author/38546958600,1
6,7,2,Chin-Hui Lee,/author/37280405600,2
7,8,1,Incorporating Ultrasound Tongue Images for Audio-Visual Speech Enhancement,/document/10418525/,1
8,9,2,Rui-Chen Zheng,/author/37090051175,1
9,10,2,Yang Ai,/author/37086348873,2
10,11,2,Zhen-Hua Ling,/author/37417702500,2
11,12,1,METTS: Multilingual Emotional Text-to-Speech by Cross-Speaker and Cross-Lingual Emotion Transfer,/document/10423864/,1
12,13,2,Xinfa Zhu,/author/37089529237,1
13,14,2,Yi Lei,/author/37088814417,1
14,15,2,Tao Li,/author/37088801358,1
15,16,2,Yongmao Zhang,/author/37089469106,1
16,17,2,Hongbin Zhou,/author/37089469471,1
17,18,2,Heng Lu,/author/37089470244,1
18,19,2,Lei Xie,/author/37288943400,3
19,20,1,AudioLDM 2: Learning Holistic Audio Generation With Self-Supervised Pretraining,/document/10530074/,1
20,21,2,Haohe Liu,/author/37089570809,1
21,22,2,Yi Yuan,/author/37090064213,1
22,23,2,Xubo Liu,/author/37089031763,1
23,24,2,Xinhao Mei,/author/37089469112,1
24,25,2,Qiuqiang Kong,/author/37086034564,1
25,26,2,Qiao Tian,/author/37089469040,1
26,27,2,Yuping Wang,/author/37089470229,1
27,28,2,Wenwu Wang,/author/37280468500,1
28,29,2,Yuxuan Wang,/author/38517620800,1
29,30,2,Mark D. Plumbley,/author/37299593000,1
30,31,1,Sample-Efficient Unsupervised Domain Adaptation of Speech Recognition Systems: A Case Study for Modern Greek,/document/10301554/,1
31,32,2,Georgios Paraskevopoulos,/author/37089471150,1
32,33,2,Theodoros Kouzelis,/author/37090080662,1
33,34,2,Georgios Rouvalis,/author/37090080719,1
34,35,2,Athanasios Katsamanis,/author/37395437200,1
35,36,2,Vassilis Katsouros,/author/37394503200,1
36,37,2,Alexandros Potamianos,/author/37284799900,1
37,38,1,Conversational Speech Recognition by Learning Audio-Textual Cross-Modal Contextual Representation,/document/10502286/,1
38,39,2,Kun Wei,/author/37088799343,1
39,40,2,Bei Li,/author/359684397152410,1
40,41,2,Hang Lv,/author/37085498409,1
41,42,2,Quan Lu,/author/37089957497,1
42,43,2,Ning Jiang,/author/37089736404,1
43,44,1,SpeechLM: Enhanced Speech Pre-Training With Unpaired Textual Data,/document/10476749/,1
44,45,2,Ziqiang Zhang,/author/37089469233,1
45,46,2,Sanyuan Chen,/author/37088934991,1
46,47,2,Long Zhou,/author/37089469873,1
47,48,2,Yu Wu,/author/37088934433,1
48,49,2,Shuo Ren,/author/37089470404,1
49,50,2,Shujie Liu,/author/37088932194,1
50,51,2,Zhuoyuan Yao,/author/37088814942,1
51,52,2,Xun Gong,/author/434938233709870,1
52,53,2,Lirong Dai,/author/37273869000,1
53,54,2,Jinyu Li,/author/37279856000,1
54,55,2,Furu Wei,/author/37085490145,1
55,56,1,Audio Super-Resolution With Robust Speech Representation Learning of Masked Autoencoder,/document/10381805/,1
56,57,2,Seung-Bin Kim,/author/37089467456,1
57,58,2,Sang-Hoon Lee,/author/37089776307,1
58,59,2,Ha-Yeong Choi,/author/974363339170890,1
59,60,2,Seong-Whan Lee,/author/37281134700,1
60,61,1,Text-Inductive Graphone-Based Language Adaptation for Low-Resource Speech Synthesis,/document/10444075/,1
61,62,2,Takaaki Saeki,/author/37088487631,1
62,63,2,Soumi Maiti,/author/37086861486,1
63,64,2,Xinjian Li,/author/37086639245,1
64,65,2,Shinji Watanabe,/author/37280302500,1
65,66,2,Shinnosuke Takamichi,/author/37085428452,1
66,67,2,Hiroshi Saruwatari,/author/37284587900,1
67,68,1,Decoupling and Interacting Multi-Task Learning Network for Joint Speech and Accent Recognition,/document/10316571/,1
68,69,2,Qijie Shao,/author/37089284259,1
69,70,2,Pengcheng Guo,/author/37086861353,1
70,71,2,Jinghao Yan,/author/37089644168,1
71,72,2,Pengfei Hu,/author/37089468132,1
72,73,1,Improving Speech Translation Accuracy and Time Efficiency With Fine-Tuned wav2vec 2.0-Based Speech Segmentation,/document/10361556/,1
73,74,2,Ryo Fukuda,/author/37089227550,1
74,75,2,Katsuhito Sudoh,/author/37087318789,1
75,76,2,Satoshi Nakamura,/author/37273963200,1
76,77,1,Text-to-Speech for Low-Resource Agglutinative Language With Morphology-Aware Language Model Pre-Training,/document/10379131/,1
77,78,2,Rui Liu,/author/37085997703,2
78,79,2,Yifan Hu,/author/37089625798,1
79,80,2,Haolin Zuo,/author/37090057761,1
80,81,2,Zhaojie Luo,/author/37085689925,1
81,82,2,Longbiao Wang,/author/37600206200,1
82,83,2,Guanglai Gao,/author/37535450500,2
83,84,1,Wav2code: Restore Clean Speech Representations via Codebook Lookup for Noise-Robust ASR,/document/10349911/,1
84,85,2,Yuchen Hu,/author/37089469553,1
85,86,2,Chen Chen,/author/37089282807,1
86,87,2,Qiushi Zhu,/author/37089469340,1
87,88,2,Eng Siong Chng,/author/37584925600,1
88,89,1,A Variance-Preserving Interpolation Approach for Diffusion Models With Applications to Single Channel Speech Enhancement and Recognition,/document/10547426/,1
89,90,2,Zilu Guo,/author/983924064253217,1
90,91,2,Jia Pan,/author/37090051105,1
91,92,2,Qing-Feng Liu,/author/37420537200,1
92,93,1,Beyond the Status Quo: A Contemporary Survey of Advances and Challenges in Audio Captioning,/document/10285526/,1
93,94,2,Xuenan Xu,/author/37088822094,1
94,95,2,Zeyu Xie,/author/37088935573,1
95,96,2,Mengyue Wu,/author/37086866287,1
96,97,2,Kai Yu,/author/38580940700,1
97,98,1,Can Pretrained English Language Models Benefit Non-English NLP Systems in Low-Resource Scenarios?,/document/10103146/,1
98,99,2,Zewen Chi,/author/37088503517,1
99,100,2,Heyan Huang,/author/37672042000,1
100,101,2,Luyang Liu,/author/37089423802,1
101,102,2,Yu Bai,/author/37085389116,1
102,103,2,Xiaoyan Gao,/author/968979386191477,1
103,104,2,Xian-Ling Mao,/author/37085359729,1
104,105,1,Personalized Adversarial Data Augmentation for Dysarthric and Elderly Speech Recognition,/document/10286152/,1
105,106,2,Zengrui Jin,/author/37089755609,1
106,107,2,Mengzhe Geng,/author/37088851068,1
107,108,2,Jiajun Deng,/author/37089776548,1
108,109,2,Tianzi Wang,/author/37089283062,1
109,110,2,Shujie Hu,/author/37089468820,1
110,111,2,Guinan Li,/author/37089468265,1
111,112,2,Xunying Liu,/author/37067675800,1
112,113,1,Data-Driven Non-Intrusive Speech Intelligibility Prediction Using Speech Presence Probability,/document/10271546/,1
113,114,2,Mathias Bach Pedersen,/author/37089431187,1
114,115,2,Søren Holdt Jensen,/author/37283443300,1
115,116,2,Zheng-Hua Tan,/author/37278529100,1
116,117,2,Jesper Jensen,/author/37271733000,1
117,118,1,Low-Latency Neural Speech Phase Prediction Based on Parallel Estimation Architecture and Anti-Wrapping Losses for Speech Generation Tasks,/document/10491381/,1
118,119,1,Large-Scale Unsupervised Audio Pre-Training for Video-to-Speech Synthesis,/document/10480633/,1
119,120,2,Triantafyllos Kefalas,/author/37088485570,1
120,121,2,Yannis Panagakis,/author/37670940200,1
121,122,2,Maja Pantic,/author/37273162000,1
122,123,1,Unified Cross-Modal Attention: Robust Audio-Visual Speech Recognition and Beyond,/document/10472123/,1
123,124,2,Jiahong Li,/author/37090052817,1
124,125,2,Chenda Li,/author/37088483386,1
125,126,2,Yifei Wu,/author/37089471199,1
126,127,2,Yanmin Qian,/author/37085386346,1
127,128,1,Statistically Guided Near-End Speech Intelligibility Improvement Through Voice Transformation and Transfer Learning,/document/10416355/,1
128,129,2,Ritujoy Biswas,/author/37088984053,1
129,130,2,Karan Nathwani,/author/38580945400,1
130,131,2,Vinayak Abrol,/author/38667324600,1
131,132,1,Controllable Accented Text-to-Speech Synthesis With Fine and Coarse-Grained Intensity Rendering,/document/10487819/,1
132,133,2,Berrak Sisman,/author/37085845983,1
133,134,2,Haizhou Li,/author/37407157000,1
134,135,1,Slowness Regularized Contrastive Predictive Coding for Acoustic Unit Discovery,/document/10400460/,1
135,136,2,Saurabhchand Bhati,/author/37086865098,1
136,137,2,Jesús Villalba,/author/37086444221,1
137,138,2,Piotr Żelasko,/author/37085363216,1
138,139,2,Laureano Moro-Velazquez,/author/37086496864,1
139,140,2,Najim Dehak,/author/37541944500,1
140,141,1,Comments on “Primary-Ambient Extraction Using Ambient Spectrum Estimation for Immersive Spatial Audio Reproduction”,/document/10301583/,1
141,142,2,Haisheng Lu,/author/37090076068,1
142,143,2,Jiangnan Liang,/author/37090076490,1
143,144,2,Chuang Shi,/author/37090076563,1
